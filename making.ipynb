{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### accuracy of clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/secondvoca/anaconda3/envs/torch/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0990990990990991"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.cat([torch.arange(10)]*100)\n",
    "# pred = torch.randint(0, 10, [1000])\n",
    "pred = torch.ones(1000)\n",
    "metrics.rand_score(y, pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### manager for 10+1 autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([7, 2, 0, 6, 1, 9, 8, 8, 0, 8])\n"
     ]
    }
   ],
   "source": [
    "class Manager:\n",
    "    def set_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### myae2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Keeper:\n",
    "    def prepare(self, less_than=10, batch_size=128, shuffle=True):\n",
    "        training_data = datasets.MNIST(\n",
    "            root=\"data\",\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=ToTensor(),\n",
    "        )\n",
    "\n",
    "        training_data.data = training_data.data[training_data.targets < less_than]\n",
    "        training_data.targets = training_data.targets[training_data.targets < less_than]\n",
    "\n",
    "        self.training_data = training_data.data / 255.0\n",
    "        self.training_targets = training_data.targets\n",
    "\n",
    "        self.training_data_length = len(training_data.data)\n",
    "\n",
    "        self.train_dataloader = DataLoader(\n",
    "            training_data, batch_size=batch_size, shuffle=shuffle\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_builder:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Manager:\n",
    "    \n",
    "\n",
    "    def set_model(self, encoder, decoder):\n",
    "        self.model = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\"encoder\", encoder),\n",
    "                    (\"decoder\", decoder),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters())\n",
    "\n",
    "    def get_cuda_device_or_cpu(self):\n",
    "        if torch.cuda.is_available():\n",
    "            cuda_count = torch.cuda.device_count()\n",
    "\n",
    "            no = 0\n",
    "            mem_available = 0\n",
    "\n",
    "            for i in range(cuda_count):\n",
    "                tmp_available = torch.cuda.mem_get_info(i)[0]\n",
    "                if mem_available < tmp_available:\n",
    "                    no = i\n",
    "                    mem_available = tmp_available\n",
    "            return f\"cuda:{no}\"\n",
    "        return \"cpu\"\n",
    "\n",
    "    def save_current_model(self, name):\n",
    "        torch.save(\n",
    "            self.model,\n",
    "            f'./models/{datetime.datetime.today().strftime(\"%Y-%m-%d %H:%M:%S\")}_{name}.pt',\n",
    "        )\n",
    "\n",
    "    def load_model(self, name):\n",
    "        self.model = torch.load(f\"./models/{name}.pt\")\n",
    "\n",
    "    def run(self, model, dataloader, optimizer, device, calc_loss):\n",
    "        hist = torch.zeros(len(dataloader))\n",
    "\n",
    "        for batch, (x, y) in enumerate(dataloader):\n",
    "            x = x.view([-1, 28 * 28]).to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # Compute prediction error\n",
    "            loss = calc_loss(model, x, y, F, device=device)\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            hist[batch] = loss.item()\n",
    "\n",
    "        return hist\n",
    "\n",
    "    def train(self, calc_loss, epochs=5, need_latent_record=False, ):\n",
    "        try:\n",
    "            device = self.get_cuda_device_or_cpu()\n",
    "        except:\n",
    "            device = \"cpu\"\n",
    "        print(f\"Now, it is working on {device}.\")\n",
    "\n",
    "        self.model.to(device)\n",
    "        self.model.train()\n",
    "\n",
    "        hist = torch.zeros(0)\n",
    "\n",
    "        for _ in tqdm(range(epochs)):\n",
    "            tmp = self.run(\n",
    "                self.model, self.train_dataloader, self.optimizer, device, calc_loss\n",
    "            )\n",
    "            hist = torch.cat([hist, tmp])\n",
    "\n",
    "        return hist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
