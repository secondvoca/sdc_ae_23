{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class My_Encoder(nn.Module):\n",
    "    def __init__(self, dim_encoder_output, activation='tanh'):\n",
    "        super().__init__()\n",
    "        if activation == \"tanh\":\n",
    "            self.activation = torch.tanh\n",
    "        self.l0 = nn.Linear(4, 4)\n",
    "        self.l1 = nn.Linear(4, dim_encoder_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.activation(self.l0(x))\n",
    "        z = self.l1(h)\n",
    "        return z\n",
    "\n",
    "\n",
    "class My_Decoder(nn.Module):\n",
    "    def __init__(self, dim_decoder_input, activation='tanh'):\n",
    "        super().__init__()\n",
    "        if activation == \"tanh\":\n",
    "            self.activation = torch.tanh\n",
    "        self.l0 = nn.Linear(dim_decoder_input, 4)\n",
    "        self.l1 = nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, z):\n",
    "        x_hat = self.activation(self.l0(z))\n",
    "        x_hat = self.l1(x_hat)\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "od = OrderedDict([\n",
    "    ('encoder',My_Encoder(2)),\n",
    "    ('decoder',My_Decoder(2))\n",
    "])\n",
    "\n",
    "model = nn.Sequential(od)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (encoder): My_Encoder(\n",
      "    (l0): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (l1): Linear(in_features=4, out_features=2, bias=True)\n",
      "  )\n",
      "  (decoder): My_Decoder(\n",
      "    (l0): Linear(in_features=2, out_features=4, bias=True)\n",
      "    (l1): Linear(in_features=4, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils._bunch.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "print(type(iris))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "print(type(iris.data))\n",
    "print(iris.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.3029, -0.1730,  0.1353, -0.0692],\n",
      "        [ 0.3013, -0.4437, -0.0029, -0.4157],\n",
      "        [ 0.3386,  0.0310, -0.2414, -0.0330],\n",
      "        [ 0.3433, -0.2415, -0.4646,  0.1265]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2804, -0.2436,  0.3656, -0.0853], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.3535,  0.1539,  0.2257, -0.1388],\n",
      "        [-0.0791, -0.2168,  0.4046,  0.1868]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2449, -0.2655], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in model.get_submodule('encoder').parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "x = torch.Tensor(iris.data)\n",
    "\n",
    "my_dataset = TensorDataset(x, x) # create your datset\n",
    "my_dataloader = DataLoader(my_dataset, batch_size=30, shuffle=True) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "for idx in range(5):\n",
    "    for x, y in my_dataloader:\n",
    "        pred = model(x)\n",
    "\n",
    "        loss = (pred - y).square().sum() / len(x)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.2881, -0.1586,  0.1506, -0.0533],\n",
      "        [ 0.3260, -0.4189,  0.0218, -0.3910],\n",
      "        [ 0.3125,  0.0048, -0.2675, -0.0591],\n",
      "        [ 0.3189, -0.2661, -0.4888,  0.1024]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2949, -0.2189,  0.3394, -0.1098], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.3803,  0.1775,  0.1989, -0.1122],\n",
      "        [-0.0540, -0.1961,  0.3797,  0.2124]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2717, -0.2907], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in model.get_submodule('encoder').parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0406, -0.5920],\n",
      "        [ 0.2950,  0.3930],\n",
      "        [-0.0942, -0.0262],\n",
      "        [ 0.4880,  0.4786]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3218, -0.2653,  0.3969, -0.0916], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.2523, -0.4001, -0.0030,  0.1688],\n",
      "        [-0.3429, -0.3876, -0.0260,  0.2116],\n",
      "        [ 0.4485,  0.1572,  0.1299, -0.3265],\n",
      "        [-0.1425,  0.1972,  0.3776,  0.4246]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.3792, -0.1653, -0.3221,  0.0607], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in model.get_submodule('decoder').parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.get_submodule('encoder').parameters():\n",
    "    p.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(5):\n",
    "    for x, y in my_dataloader:\n",
    "        pred = model(x)\n",
    "\n",
    "        loss = (pred - y).square().sum() / len(x)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.2927, -0.1633,  0.1465, -0.0569],\n",
      "        [ 0.3349, -0.4100,  0.0307, -0.3820],\n",
      "        [ 0.3020, -0.0057, -0.2780, -0.0696],\n",
      "        [ 0.3102, -0.2748, -0.4973,  0.0940]])\n",
      "Parameter containing:\n",
      "tensor([ 0.2902, -0.2100,  0.3290, -0.1185])\n",
      "Parameter containing:\n",
      "tensor([[ 0.3913,  0.1818,  0.1880, -0.1010],\n",
      "        [-0.0447, -0.1924,  0.3705,  0.2224]])\n",
      "Parameter containing:\n",
      "tensor([-0.2827, -0.3001])\n",
      "Parameter containing:\n",
      "tensor([[-0.0670, -0.6208],\n",
      "        [ 0.3209,  0.4093],\n",
      "        [-0.1237, -0.0587],\n",
      "        [ 0.4664,  0.4708]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3473, -0.2905,  0.4254, -0.0709], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 2.8106e-01, -4.2777e-01,  2.2757e-02,  1.4150e-01],\n",
      "        [-3.1408e-01, -4.1535e-01, -1.7625e-04,  1.8435e-01],\n",
      "        [ 4.7696e-01,  1.2965e-01,  1.5551e-01, -3.5375e-01],\n",
      "        [-1.1386e-01,  1.6946e-01,  4.0353e-01,  3.9710e-01]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.3544, -0.1404, -0.2975,  0.0857], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in model.get_submodule('encoder').parameters():\n",
    "    print(p)\n",
    "for p in model.get_submodule('decoder').parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.2927, -0.1633,  0.1465, -0.0569],\n",
      "        [ 0.3349, -0.4100,  0.0307, -0.3820],\n",
      "        [ 0.3020, -0.0057, -0.2780, -0.0696],\n",
      "        [ 0.3102, -0.2748, -0.4973,  0.0940]])\n",
      "Parameter containing:\n",
      "tensor([ 0.2902, -0.2100,  0.3290, -0.1185])\n",
      "Parameter containing:\n",
      "tensor([[ 0.3913,  0.1818,  0.1880, -0.1010],\n",
      "        [-0.0447, -0.1924,  0.3705,  0.2224]])\n",
      "Parameter containing:\n",
      "tensor([-0.2827, -0.3001])\n",
      "Parameter containing:\n",
      "tensor([[-0.0921, -0.6457],\n",
      "        [ 0.3460,  0.4341],\n",
      "        [-0.1489, -0.0838],\n",
      "        [ 0.4431,  0.4512]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3724, -0.3156,  0.4507, -0.0476], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.3061, -0.4528,  0.0478,  0.1168],\n",
      "        [-0.2890, -0.4404,  0.0249,  0.1596],\n",
      "        [ 0.5019,  0.1047,  0.1805, -0.3784],\n",
      "        [-0.0891,  0.1447,  0.4284,  0.3726]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.3294, -0.1155, -0.2726,  0.1104], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "for idx in range(5):\n",
    "    for x, y in my_dataloader:\n",
    "        pred = model(x)\n",
    "\n",
    "        loss = (pred - y).square().sum() / len(x)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "for p in model.get_submodule('encoder').parameters():\n",
    "    print(p)\n",
    "for p in model.get_submodule('decoder').parameters():\n",
    "    print(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
